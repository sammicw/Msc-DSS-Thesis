{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "757a84ad-87f8-46fb-8854-71efed4f1549",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import Packages \n",
    "import pandas as pd\n",
    "from pandas.core.common import flatten\n",
    "import numpy as np\n",
    "from numpy.random import seed\n",
    "from math import sqrt\n",
    "import matplotlib.pyplot as plt\n",
    "import statistics\n",
    "from scipy.stats import uniform, randint \n",
    "from scipy.stats.mstats import winsorize\n",
    "\n",
    "import sklearn\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV, cross_val_score, KFold\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "#from sklearn.datasets import make_regression\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Activation, Dense, BatchNormalization, Dropout, AlphaDropout\n",
    "\n",
    "import keras_tuner\n",
    "from keras_tuner import Objective\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "seed(10)\n",
    "np.random.seed(10)\n",
    "tf.random.set_seed(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b65f4693-687e-493f-ad40-7f6a020c4968",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create Functions for Evaluation\n",
    "\n",
    "def mse(actual_ret, pred_ret):\n",
    "    d = (actual_ret - pred_ret)**2\n",
    "    mse = sum(d) / len(d)\n",
    "    return mse\n",
    "\n",
    "\n",
    "def mae(actual_ret, pred_ret):\n",
    "    d = (actual_ret - pred_ret)\n",
    "    mae = sum(abs(d)) / len(d)\n",
    "    return mae\n",
    "    \n",
    "def rmse(actual_ret, pred_ret):\n",
    "    d = (actual_ret - pred_ret)**2\n",
    "    mse = sum(d) / len(d)\n",
    "    rmse = sqrt(mse)\n",
    "    return rmse\n",
    "\n",
    "def r_sq(actual_ret, pred_ret):\n",
    "    nom = sum((actual_ret - pred_ret)**2)\n",
    "    denom = sum(actual_ret**2) # Note that R2 is demeaned\n",
    "    r_sq = (1 - (nom / denom)) * 100\n",
    "    return r_sq\n",
    "\n",
    "# Calculate the percentage of correct sign predictions\n",
    "def pcp(actual_ret, pred_ret):\n",
    "    num_correct = sum((pred > 0) == (actual > 0) for pred, actual in zip(pred_ret, actual_ret))\n",
    "    pcp = (num_correct / len(pred_ret)) * 100\n",
    "    return pcp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "id": "b60f4fa7-490d-4734-af48-c1f0ba35871b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Specify the Models: We are iterating each algorithm through these four models\n",
    "\n",
    "# To select the target variable e.g., find target variable in train set or test set\n",
    "def find_target(df):\n",
    "    df = df.reset_index(drop=True)\n",
    "    target = df['ret+1']\n",
    "    return target\n",
    "\n",
    "# To select the predictors from the baseline model which excludes sentiment \n",
    "def find_baseline(df):\n",
    "    df = df.reset_index(drop=True)\n",
    "    baseline = df[['cshoc', 'cshtrd', 'eps', 'prccd', 'prchd', 'prcld', 'prcod', 'div']]\n",
    "    return baseline\n",
    "\n",
    "# To select the predictors from the Model 1 which includes the sentiment from Twitter \n",
    "def find_model_1(df):\n",
    "    df = df.reset_index(drop=True)\n",
    "    model_1 = df[['cshoc', 'cshtrd', 'eps', 'prccd', 'prchd', 'prcld', 'prcod', 'div', 'tweets_sent']]\n",
    "    return model_1\n",
    "\n",
    "# To select the predictors from the Model 2 which includes the sentiment from News Articles\n",
    "def find_model_2(df):\n",
    "    df = df.reset_index(drop=True)\n",
    "    model_2 = df[['cshoc', 'cshtrd', 'eps', 'prccd', 'prchd', 'prcld', 'prcod', 'div', 'news_sent']]\n",
    "    return model_2\n",
    "\n",
    "# To select the predictors from the Model 3 which includes the sentiment from News Articles\n",
    "def find_model_3(df):\n",
    "    df = df.reset_index(drop=True)\n",
    "    model_3 = df[['cshoc', 'cshtrd', 'eps', 'prccd', 'prchd', 'prcld', 'prcod', 'div', 'tweets_sent', 'news_sent']]\n",
    "    return model_3\n",
    "\n",
    "# Create list of functions\n",
    "models_functions = [find_baseline, find_model_1, find_model_2, find_model_3] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c02bdf53-84c4-4a34-94bb-e32ee1f0251c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Tweets\n",
    "df = pd.read_csv(\"ml_df.csv\", lineterminator='\\n')\n",
    "\n",
    "# Sort Observations \n",
    "df = df.sort_values(['date', 'company'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "da6dd1e8-0346-40ec-92aa-ad33b38c8dc3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    16320.000000\n",
      "mean        -0.009796\n",
      "std          4.730521\n",
      "min       -302.139417\n",
      "1%          -7.238147\n",
      "25%         -1.104501\n",
      "50%          0.088598\n",
      "75%          1.280240\n",
      "99%          7.325540\n",
      "max         20.930742\n",
      "Name: ret+1, dtype: float64\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Shows the extreme values in target variable\n",
    "print(df['ret+1'].describe([0.01, 0.25, 0.5, 0.75, 0.99]))\n",
    "\n",
    "# Winsorize extreme returns to reduce skewness and effect of outliers\n",
    "for v in ['ret+1']:\n",
    "    df[v] = winsorize(df[v],limits=[.005, .005])\n",
    "\n",
    "# Shows distribution of returns after winsorization\n",
    "plt.hist(df['ret+1'], 25)\n",
    "plt.show()\n",
    "\n",
    "# Set date as index to slice dataframe \n",
    "df = df.set_index(['date', 'company'])\n",
    "\n",
    "# Split Data into Train and Test Set\n",
    "train = df['2021-01-01':'2022-08-31']\n",
    "test = df['2022-09-01':'2023-03-20']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8bb32c74-3982-4a66-bfce-35f3c8f53dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Baseline Model: Linear Regression\n",
    "models_functions = [find_baseline, find_model_1, find_model_2, find_model_3] \n",
    "lr_pred = [] # To save the predictions of each models into a list\n",
    "\n",
    "for mod in models_functions:\n",
    "    model = LinearRegression().fit(mod(train), find_target(train)) \n",
    "\n",
    "    pred = model.predict(mod(test))\n",
    "    lr_pred.append(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "22e62102-f11c-4c4e-829f-ac346733ac68",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r2: -0.0817\n",
      "mse: 6.1579\n",
      "rmse: 2.4815\n",
      "mae: 1.7954\n",
      "pcp: 50.438\n",
      "\n",
      "r2: -0.1358\n",
      "mse: 6.1612\n",
      "rmse: 2.4822\n",
      "mae: 1.796\n",
      "pcp: 48.8321\n",
      "\n",
      "r2: -0.0993\n",
      "mse: 6.159\n",
      "rmse: 2.4817\n",
      "mae: 1.7959\n",
      "pcp: 49.854\n",
      "\n",
      "r2: -0.1528\n",
      "mse: 6.1622\n",
      "rmse: 2.4824\n",
      "mae: 1.7965\n",
      "pcp: 48.3212\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Results for Baseline Model\n",
    "for i in range(0, 4):\n",
    "    print(\"r2:\", round(r_sq(find_target(test), lr_pred[i]), 4))\n",
    "    print(\"mse:\", round(mse(find_target(test), lr_pred[i]), 4))\n",
    "    print(\"rmse:\", round(rmse(find_target(test), lr_pred[i]), 4))\n",
    "    print(\"mae:\", round(mae(find_target(test), lr_pred[i]), 4))\n",
    "    print(\"pcp:\", round(pcp(find_target(test), lr_pred[i]), 4))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "12be8e06-0c69-4eb1-9bd6-8e0bf8d1ee2c",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Results from Random Search \n",
      "\n",
      " The best estimator across ALL searched params:\n",
      " RandomForestRegressor(max_depth=316, max_leaf_nodes=8, min_samples_leaf=6,\n",
      "                      n_estimators=300)\n",
      "\n",
      " The best score across ALL searched params:\n",
      " -4.987470998795036\n",
      "\n",
      " The best parameters across ALL searched params:\n",
      " {'max_depth': 316, 'max_leaf_nodes': 8, 'min_samples_leaf': 6, 'n_estimators': 300}\n",
      " Results from Random Search \n",
      "\n",
      " The best estimator across ALL searched params:\n",
      " RandomForestRegressor(max_depth=315, max_leaf_nodes=5, min_samples_leaf=19,\n",
      "                      n_estimators=400)\n",
      "\n",
      " The best score across ALL searched params:\n",
      " -4.988925968380372\n",
      "\n",
      " The best parameters across ALL searched params:\n",
      " {'max_depth': 315, 'max_leaf_nodes': 5, 'min_samples_leaf': 19, 'n_estimators': 400}\n",
      " Results from Random Search \n",
      "\n",
      " The best estimator across ALL searched params:\n",
      " RandomForestRegressor(max_depth=314, max_leaf_nodes=8, min_samples_leaf=13,\n",
      "                      n_estimators=200)\n",
      "\n",
      " The best score across ALL searched params:\n",
      " -4.98762268521304\n",
      "\n",
      " The best parameters across ALL searched params:\n",
      " {'max_depth': 314, 'max_leaf_nodes': 8, 'min_samples_leaf': 13, 'n_estimators': 200}\n",
      " Results from Random Search \n",
      "\n",
      " The best estimator across ALL searched params:\n",
      " RandomForestRegressor(max_depth=316, max_leaf_nodes=8, min_samples_leaf=6,\n",
      "                      n_estimators=300)\n",
      "\n",
      " The best score across ALL searched params:\n",
      " -4.987189478764034\n",
      "\n",
      " The best parameters across ALL searched params:\n",
      " {'max_depth': 316, 'max_leaf_nodes': 8, 'min_samples_leaf': 6, 'n_estimators': 300}\n"
     ]
    }
   ],
   "source": [
    "# Random Forest\n",
    "rf_pred = []\n",
    "\n",
    "for mod in models_functions:\n",
    "    \n",
    "    parameters = {'n_estimators': [100, 200, 300, 400],\n",
    "                  'max_depth': randint(300, 350),\n",
    "                  'min_samples_leaf': randint(1, 50),\n",
    "                  'max_leaf_nodes': randint(5, 15)}\n",
    "     \n",
    "    randm_src = RandomizedSearchCV(RandomForestRegressor(),\n",
    "                                   param_distributions = parameters, \n",
    "                                   scoring = 'neg_mean_squared_error',\n",
    "                                   n_iter = 30,\n",
    "                                   n_jobs = -1, \n",
    "                                   refit = True, \n",
    "                                   random_state = 0,\n",
    "                                   return_train_score = True,\n",
    "                                   cv = 5,\n",
    "                                   error_score = 'raise')\n",
    "    \n",
    "    model = randm_src.fit(mod(train), find_target(train))\n",
    "    \n",
    "    print(\" Results from Random Search \")\n",
    "    print(\"\\n The best estimator across ALL searched params:\\n\", randm_src.best_estimator_)\n",
    "    print(\"\\n The best score across ALL searched params:\\n\", randm_src.best_score_)\n",
    "    print(\"\\n The best parameters across ALL searched params:\\n\", randm_src.best_params_)\n",
    "\n",
    "    pred = model.predict(mod(test))\n",
    "    rf_pred.append(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "7aa2a249-d1f7-453c-89f4-230c8cfc710a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r2: 0.1967\n",
      "mse: 6.1407\n",
      "rmse: 2.4781\n",
      "mae: 1.793\n",
      "pcp: 51.6423\n",
      "\n",
      "r2: 0.1875\n",
      "mse: 6.1413\n",
      "rmse: 2.4782\n",
      "mae: 1.7925\n",
      "pcp: 51.5693\n",
      "\n",
      "r2: 0.2518\n",
      "mse: 6.1373\n",
      "rmse: 2.4774\n",
      "mae: 1.7919\n",
      "pcp: 51.7883\n",
      "\n",
      "r2: 0.2158\n",
      "mse: 6.1396\n",
      "rmse: 2.4778\n",
      "mae: 1.7928\n",
      "pcp: 51.2774\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Results for Random Forest\n",
    "for i in range(0, 4):\n",
    "    print(\"r2:\", round(r_sq(find_target(test), rf_pred[i]), 4))\n",
    "    print(\"mse:\", round(mse(find_target(test), rf_pred[i]), 4))\n",
    "    print(\"rmse:\", round(rmse(find_target(test), rf_pred[i]), 4))\n",
    "    print(\"mae:\", round(mae(find_target(test), rf_pred[i]), 4))\n",
    "    print(\"pcp:\", round(pcp(find_target(test), rf_pred[i]), 4))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "5a919364-3fcd-45e2-84e8-64d0b68e9aed",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Results from Random Search \n",
      "Best estimator:  GradientBoostingRegressor(learning_rate=0.005, max_depth=177, max_leaf_nodes=28,\n",
      "                          min_samples_leaf=10)\n",
      "Best parameters:  {'learning_rate': 0.005, 'max_depth': 177, 'max_leaf_nodes': 28, 'min_samples_leaf': 10, 'n_estimators': 100}\n",
      "Best score:  -4.99324924813404\n",
      " Results from Random Search \n",
      "Best estimator:  GradientBoostingRegressor(learning_rate=0.005, max_depth=177, max_leaf_nodes=28,\n",
      "                          min_samples_leaf=10)\n",
      "Best parameters:  {'learning_rate': 0.005, 'max_depth': 177, 'max_leaf_nodes': 28, 'min_samples_leaf': 10, 'n_estimators': 100}\n",
      "Best score:  -4.993380052213871\n",
      " Results from Random Search \n",
      "Best estimator:  GradientBoostingRegressor(learning_rate=0.005, max_depth=177, max_leaf_nodes=28,\n",
      "                          min_samples_leaf=10)\n",
      "Best parameters:  {'learning_rate': 0.005, 'max_depth': 177, 'max_leaf_nodes': 28, 'min_samples_leaf': 10, 'n_estimators': 100}\n",
      "Best score:  -4.989348696934921\n",
      " Results from Random Search \n",
      "Best estimator:  GradientBoostingRegressor(learning_rate=0.005, max_depth=177, max_leaf_nodes=28,\n",
      "                          min_samples_leaf=10)\n",
      "Best parameters:  {'learning_rate': 0.005, 'max_depth': 177, 'max_leaf_nodes': 28, 'min_samples_leaf': 10, 'n_estimators': 100}\n",
      "Best score:  -4.992400957861397\n"
     ]
    }
   ],
   "source": [
    "# Gradient Boosting Regression Tree\n",
    "gbrt_pred = []\n",
    "\n",
    "for mod in models_functions: \n",
    "    parameters = {'n_estimators': [100, 200, 300, 400],\n",
    "                  'max_depth':  randint(100, 200),\n",
    "                  'min_samples_leaf': randint(1, 20),\n",
    "                  'max_leaf_nodes': randint(20, 50),\n",
    "                  'learning_rate': [0.01, 0.005]\n",
    "                 }\n",
    "    \n",
    "    random_search = RandomizedSearchCV(GradientBoostingRegressor(),\n",
    "                                       param_distributions = parameters,\n",
    "                                       scoring = 'neg_mean_squared_error',\n",
    "                                       n_iter = 30,\n",
    "                                       n_jobs = -1,\n",
    "                                       refit = True,\n",
    "                                       random_state = 0,\n",
    "                                       return_train_score = True,\n",
    "                                       cv = 5,\n",
    "                                       error_score = 'raise')\n",
    "        \n",
    "    model = random_search.fit(mod(train), find_target(train))\n",
    "        \n",
    "    print(\" Results from Random Search \")\n",
    "    print(\"Best estimator: \", random_search.best_estimator_)\n",
    "    print(\"Best parameters: \", random_search.best_params_)\n",
    "    print(\"Best score: \", random_search.best_score_)\n",
    "\n",
    "    pred = model.predict(mod(test))\n",
    "    gbrt_pred.append(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "9ee42897",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r2: -0.0403\n",
      "mse: 6.1553\n",
      "rmse: 2.481\n",
      "mae: 1.7944\n",
      "pcp: 51.5328\n",
      "\n",
      "r2: 0.1413\n",
      "mse: 6.1441\n",
      "rmse: 2.4787\n",
      "mae: 1.7925\n",
      "pcp: 52.7737\n",
      "\n",
      "r2: 0.0422\n",
      "mse: 6.1502\n",
      "rmse: 2.48\n",
      "mae: 1.7934\n",
      "pcp: 51.5693\n",
      "\n",
      "r2: 0.214\n",
      "mse: 6.1397\n",
      "rmse: 2.4778\n",
      "mae: 1.7923\n",
      "pcp: 51.9708\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Results for Gradient Boosted Regression \n",
    "for i in range(0, 4):\n",
    "    print(\"r2:\", round(r_sq(find_target(test), gbrt_pred[i]), 4))\n",
    "    print(\"mse:\", round(mse(find_target(test), gbrt_pred[i]), 4))\n",
    "    print(\"rmse:\", round(rmse(find_target(test), gbrt_pred[i]), 4))\n",
    "    print(\"mae:\", round(mae(find_target(test), gbrt_pred[i]), 4))\n",
    "    print(\"pcp:\", round(pcp(find_target(test), gbrt_pred[i]), 4))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "id": "277f03fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results from Random Search \n",
      "Best estimator:  <keras.wrappers.scikit_learn.KerasRegressor object at 0x0000018294C10340>\n",
      "Best parameters:  {'layer_2': 32, 'layer_1': 32, 'l2': 1e-05, 'l1': 0, 'dropout_rate_1': 0.4}\n",
      "Best score:  -4.977510690689087\n",
      "Results from Random Search \n",
      "Best estimator:  <keras.wrappers.scikit_learn.KerasRegressor object at 0x00000182B58B0C10>\n",
      "Best parameters:  {'layer_2': 256, 'layer_1': 8, 'l2': 1e-05, 'l1': 0, 'dropout_rate_1': 0.3}\n",
      "Best score:  -4.976974272727967\n",
      "Results from Random Search \n",
      "Best estimator:  <keras.wrappers.scikit_learn.KerasRegressor object at 0x00000182B5A3B1F0>\n",
      "Best parameters:  {'layer_2': 8, 'layer_1': 256, 'l2': 0, 'l1': 1e-05, 'dropout_rate_1': 0.2}\n",
      "Best score:  -4.974345469474793\n",
      "Results from Random Search \n",
      "Best estimator:  <keras.wrappers.scikit_learn.KerasRegressor object at 0x0000018295DCBE50>\n",
      "Best parameters:  {'layer_2': 128, 'layer_1': 256, 'l2': 0, 'l1': 0, 'dropout_rate_1': 0.1}\n",
      "Best score:  -4.975479054450989\n"
     ]
    }
   ],
   "source": [
    "# Neural Network - 2 Layer\n",
    "nn2_pred = []\n",
    "\n",
    "for mod in models_functions:\n",
    "\n",
    "    parameters = {'layer_1': [256, 128, 64, 32, 16, 8],\n",
    "                  'layer_2': [256, 128, 64, 32, 16, 8],\n",
    "                  'l1': [0, 1e-3, 1e-4, 1e-5], # L1, L2 -> extreme negative R2 and extreme high MSE\n",
    "                  'l2': [0, 1e-3, 1e-4, 1e-5],\n",
    "                  'dropout_rate_1': [0.1, 0.2, 0.3, 0.4] # Grid found rate = 0 is the best\n",
    "                 } \n",
    "    \n",
    "    def build_model(layer_1, layer_2, l1, l2, dropout_rate_1):\n",
    "        model = Sequential()\n",
    "        model.add(Dense(units = layer_1, \n",
    "                        activation = 'relu', \n",
    "                        input_shape = mod(train).shape[1:],\n",
    "                        kernel_regularizer = regularizers.L1L2(l1, l2)))\n",
    "        model.add(keras.layers.AlphaDropout(dropout_rate_1))\n",
    "        model.add(keras.layers.BatchNormalization())\n",
    "        \n",
    "        model.add(Dense(units = layer_2, \n",
    "                        activation = 'relu', \n",
    "                        input_shape = mod(train).shape[1:],\n",
    "                        kernel_regularizer = regularizers.L1L2(l1, l2)))\n",
    "        model.add(keras.layers.AlphaDropout(dropout_rate_1))\n",
    "        model.add(keras.layers.BatchNormalization())\n",
    "    \n",
    "        model.add(Dense(1, activation = 'linear'))\n",
    "        model.compile(optimizer = 'adam', loss = 'mse', metrics=[tf.keras.metrics.MeanSquaredError()])\n",
    "        return model\n",
    "\n",
    "    regressor = keras.wrappers.scikit_learn.KerasRegressor(build_fn = build_model,\n",
    "                                                           epochs = 20,\n",
    "                                                           verbose = 0,\n",
    "                                                           batch_size = 256) # Higher batch -> Negative R2\n",
    "    \n",
    "\n",
    "    random_search = RandomizedSearchCV(estimator = regressor,\n",
    "                                       param_distributions = parameters,\n",
    "                                       cv = 10,\n",
    "                                       n_iter = 20)\n",
    "\n",
    "    early_stopping1 = EarlyStopping(monitor='mean_squared_error', patience = 3, restore_best_weights=True)\n",
    "    early_stopping2 = EarlyStopping(monitor='mean_squared_error', patience = 15, restore_best_weights=True)\n",
    "    random_search.fit(mod(train), find_target(train), callbacks = [early_stopping1]) \n",
    "\n",
    "    print(\"Results from Random Search \")\n",
    "    print(\"Best estimator: \", random_search.best_estimator_)\n",
    "    print(\"Best parameters: \", random_search.best_params_)\n",
    "    print(\"Best score: \", random_search.best_score_)\n",
    "    \n",
    "    model = random_search.best_estimator_\n",
    "    model.set_params(epochs = 100)\n",
    "    model.fit(mod(train), find_target(train), callbacks = [early_stopping2])\n",
    "    \n",
    "    pred = model.predict(mod(test))\n",
    "    nn2_pred.append(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "id": "86a1bf42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r2: 0.022\n",
      "mse: 6.1515\n",
      "rmse: 2.4802\n",
      "mae: 1.7933\n",
      "pcp: 50.6204\n",
      "\n",
      "r2: 0.0219\n",
      "mse: 6.1515\n",
      "rmse: 2.4802\n",
      "mae: 1.7933\n",
      "pcp: 51.0219\n",
      "\n",
      "r2: 0.0319\n",
      "mse: 6.1509\n",
      "rmse: 2.4801\n",
      "mae: 1.7934\n",
      "pcp: 50.5474\n",
      "\n",
      "r2: 0.0386\n",
      "mse: 6.1505\n",
      "rmse: 2.48\n",
      "mae: 1.7933\n",
      "pcp: 50.219\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(0, 4):\n",
    "    print(\"r2:\", round(r_sq(find_target(test), nn2_pred[i]), 4))\n",
    "    print(\"mse:\", round(mse(find_target(test), nn2_pred[i]), 4))\n",
    "    print(\"rmse:\", round(rmse(find_target(test), nn2_pred[i]), 4))\n",
    "    print(\"mae:\", round(mae(find_target(test), nn2_pred[i]), 4))\n",
    "    print(\"pcp:\", round(pcp(find_target(test), nn2_pred[i]), 4))\n",
    "    print() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "cfb7fa63-60ed-451a-8e09-201a295afe02",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_list = [lr_pred, rf_pred, gbrt_pred, nn2_pred]\n",
    "\n",
    "def to_dataframe(df):\n",
    "    df = pd.DataFrame(np.transpose(df))\n",
    "    return df\n",
    "\n",
    "for p in pred_list:\n",
    "    p = to_dataframe(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "id": "a5e97ff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save as CSV\n",
    "#test_data = test.reset_index(drop=False)\n",
    "#test_data = test_data[['date', 'company', 'ret+1']]\n",
    "#test_data.to_csv(\"actual_ret.csv\", index = False)\n",
    "#lr_pred.to_csv(\"lr_pred.csv\", index = False)\n",
    "#gbrt_pred.to_csv(\"gbrt_pred.csv\", index = False)\n",
    "#rf_pred.to_csv(\"rf_pred.csv\", index = False)\n",
    "#nn1_pred.to_csv(\"nn1_pred.csv\", index = False)\n",
    "#nn2_pred.to_csv(\"nn2_pred.csv\", index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
